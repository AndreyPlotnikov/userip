Тестовое задание
================


Описание подхода к реализации
-----------------------------

Анализ связей между пользователями и веб-сервис разделены друг от друга.
Веб-сервис просто делает запрос в таблицу users_link по первичному ключу (user_id1, user_id2), 
которая уже содержит информацию о связях пользователей.
 
Анализатор сделан просто как джанго-команда, которая запускается по крону.
На каждой итерации, он берет из исходной таблицы user_ip новые записи и добавляет/обновляет данные в users_link.
В текущей реализации, предполагается одновременная работа только одного экземпляра.
На время работы выставляется лок, так что параллельный запуск 2-х и более экземпляров не возможен.
Поэтому можно смело прописывать в крон запуск команды хоть каждую минуту.
При каждом запуске, по умолчанию, команды пытается выбрать все новые данные, но это можно ограничить с помощью параметра.

Можно доработать реализацию так, чтобы была возможность запускать сразу несколько экземпляров.

Еще можно предложить вариант с job-сервером, например, Celery.
Один процесс выгребает новые данные, разбивает на пачки и раздает как задания.


Установка и запуск
------------------

```
> virtualenv ve
> source ve/bin/activate
> pip install -r requirements.txt
> psql -d postgres -c "create database userip"
> psql -d userip < userip.sql
> ./manage.py runserver 8080
```

Генерация исходных данных и запуск анализатора:

```
> python ipgen.py 100000
> ./manage.py linkanalyze
```

Запрос к веб-сервису: `http://localhost:8080/userip/link/user1=1234&user2=4567`